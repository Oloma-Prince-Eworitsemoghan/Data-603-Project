---
title: "DATA 603 Project - Group 6"
date: "2025-03-28"
output: 
  pdf_document:
    latex_engine: xelatex
author: 
  - "Group 6"
---
1. INTRODUCTION

1.1 MOTIVATION

The housing market has been fairly inconsistent lately in various regions around the world. Prices have skyrocketed and it has become very difficult for young home owners to purchase homes. We are looking into this housing data in Boston to gain an idea of what factors are considered in the valuation of houses and what prospective homeowners should look out for when trying to buy a house.

1.1.1 Context

The domains for this project is real estate analytics, urban economics, and  urban planning. This project would explore the relationships between housing prices in Boston and various features that may influence them. Our dataset was obtained from a census survey conducted in the 1970s. We are planning on running several different regression procedures to get a better understanding of how our dependent variable Median Value (measured in thousands) is effected by the 13 independent variables. 

1.1.2 Problem

The problem we hope to address is figuring out which variables are most influential in predicting the median value. We have 13 different variables, and we do not know at this time if they are all relevant.The problem would be addressed by exploring the dataset to determine the features that significantly influence housing prices. The project will also provide insights into how the identified significant variables interact with the prices.

Some of the data/visual analytics we aim to display are:
>pairs-plot 
>gg plot2 


1.1.3 Challenges


1.2 OBJECTIVES

1.2.1 Overview


1.2.2 Goals & Research Questions
Our goal is to develop a multiple linear regression model that accurately predicts house prices based on significant features.



2. METHODOLOGY
2.1 Data
2.2 Approach
2.3 Workflow

```{r}
library(mctest)
library(ggplot2)
library(GGally)
library(car)
library(olsrr)
library(lmtest)
```



a. Testing for Multicolinearity
```{r}
boston_data= read.csv("./BostonHousing.csv")
head(boston_data)
```


```{r}
boston_data$chas[which(boston_data$chas==0)] = "No"
boston_data$chas[which(boston_data$chas==1)] = "Yes"
```


```{r}
boston_additive = lm(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+b+lstat, data= boston_data)

imcdiag(boston_additive, method = "VIF")
```
Based off of our results. Multicolinearity was not detected for any of the variables. 

```{r}
library(knitr)
anova_table <- data.frame(
  "Variable Name" = c("crim","zn","indus","chas","nox","rm","age","dis","rad","tax","ptratio","b","lstat"),
  "VIF" = c(1.7922,2.2928,3.9916,1.0740,4.3937,1.9337,3.1008,3.9559,7.4845,9.0086,1.7991,1.3485,2.9415),
  "Detection" = c(0,0,0,0,0,0,0,0,0,0,0,0,0)
)
kable(anova_table, caption = "TEST FOR MULTICOLINEARITY")
```




b. Additive model
```{r}
summary(boston_additive)
```
Using and individual t-test with the hypothesis: 

$H_0 = \beta_1\ = \beta_2\ = \beta_p\ =0$

$H_A = at least one \beta_i\ is not zero (i=1,2,...p)$

The p-value for indus and age are  0.738288 and 0.958229, respectively. Because the p-value is greater than our $\alpha$ of 0.05, we fail to reject the null and beta values for these variables are determined to be insignificant.

```{r}
reduced_additive_model = lm(formula = medv ~ crim + zn + factor(chas) + nox + rm+ dis + rad + tax + ptratio + b + lstat, data = boston_data)
summary(reduced_additive_model)
```

All of our variables seem to be significant. 

We will verify that dropping these variables makes sense using a global f-test/anova. 

```{r}
table1 = data.frame((anova(reduced_additive_model,boston_additive)))
print(table1)
```
The hypothesis for the f-test is: 

For the f test the hypothesis is:

Hypotheses
$$
\begin{aligned}
H_0&:\beta_i=0\\
H_a&:\beta_i\neq0 (i=1,2,...,p)
\end{aligned}
$$

Since the p_value is 0.9443 which is greater than 0.05, this indicates that we do not have enough evidence against the null hypothesis. Therefore, we can conclude that the reduced model is preferred.

```{r}
stepmod=ols_step_both_p(boston_additive,p_enter = 0.05, p_remove = 0.1, details=FALSE)
summary(stepmod$model)
```

c. Final Additive model (F-test, anova table)

Our final additive model is: 

$\hat{medv} = 36.341145 - 0.108413crim_{i} +0.045845zn_{i} +2.718716chas_{i} -17.376023nox_{i} + 3.801579rm_{i} -1.492711dis_{i} + 0.299608rad_{i} -0.011778tax_{i} -0.946525ptratio_{i} +0.009291b_{i} - 0.522553lstat_{i}$


d. Interaction model

```{r}
interaction_model = lm(formula = medv ~ (crim + zn + chas + nox + rm+ dis + rad + tax + ptratio + b + lstat)^2, data = boston_data)
summary(interaction_model)
```


```{r}
reduced_interaction_model = lm(formula = medv ~ crim + zn + chas + nox + rm+ dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas + crim:nox + crim:rm+ crim:dis +crim:rad+ crim:tax+ crim:b +crim:lstat + zn:dis + zn:tax + chas:nox +chas:rm +chas:lstat + nox:rad + nox:tax+ rm:dis + rm:ptratio+ rm:b+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(reduced_interaction_model)
```

```{r}
reduced_interaction_model2 = lm(formula = medv ~ crim + zn + chas + nox + rm+ dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + nox:tax+ rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(reduced_interaction_model2)
```


```{r}
reduced_interaction_model3 = lm(formula = medv ~ crim + zn + chas + nox + rm+ dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(reduced_interaction_model3)
```


```{r}
table2= data.frame((anova(reduced_interaction_model3,interaction_model)))
print(table2)
```

```{r}
stepmodinter=ols_step_both_p(interaction_model,p_enter = 0.05, p_remove = 0.1, details=FALSE)
summary(stepmodinter$model)
```

```{r}
table3 = data.frame((anova(stepmodinter$model,interaction_model)))
print(table3)
```


Based on the summary above, the p-value is $8.242e-12<0.05$, suggesting the null hypothesis should be rejected. Also, the adjusted $R^2_{adj}$ and RSE of the full interaction model are 0.888 and 3.078 respectively, while the adjusted $R^2_{adj}$ and RSE of the reduced interaction model are 0.8627 and 3.408 respectively. 

These suggest the full interaction model should be preferred. However, the full interaction model has a number of insignificant interactions, while the reduced interaction model has only significant interactions. Even though the anova test, adjusted $R^2_{adj}$ and RSE suggest preferring the full interaction model, there isn't a major difference between the adjusted $R^2_{adj}$ and RSE of the two models.

We would choose the reduced model because it retains all significant interactions while eliminating insignificant ones, ensuring better interpretability and avoiding unnecessary complexity without a substantial loss in explanatory power.



# HIGHER ORDER EXPLORATION

```{r}
library(GGally)
```


```{r}
higher_order_data = data.frame(boston_data$medv, boston_data$crim, boston_data$zn, boston_data$chas, boston_data$nox, boston_data$rm, boston_data$dis, boston_data$rad, boston_data$tax, boston_data$ptratio, boston_data$b, boston_data$lstat)

ggpairs(higher_order_data,lower = list(continuous = wrap("smooth_loess", color = "red"), combo = "facethist", discrete = "facetbar", na = "na"))
```

It looks like the variables that might be worth exploring for possible higher order relationships with medv are crim, zn, nox, rm, dis, rad, tax, lstat


```{r}
higher_order_crim_2 = lm(formula = medv ~ crim + I(crim^2) + zn + chas + nox + rm+ dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_crim_2)
```

```{r}
higher_order_crim_3 = lm(formula = medv ~ crim + I(crim^2) + I(crim^3) + zn + chas + nox + rm+ dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_crim_3)
```

```{r}
higher_order_zn_2 = lm(formula = medv ~ crim + zn + I(zn^2) + chas + nox + rm+ dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_zn_2)
```

```{r}
higher_order_nox_2 = lm(formula = medv ~ crim + zn + chas + nox + I(nox^2) + rm+ dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_nox_2)
```

```{r}
higher_order_nox_3 = lm(formula = medv ~ crim + zn + chas + nox + I(nox^2) + I(nox^3) + rm+ dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_nox_3)
```


```{r}
higher_order_rm_2 = lm(formula = medv ~ crim + zn + chas + nox + rm+ I(rm^2)+ dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_rm_2)
```

```{r}
higher_order_rm_3 = lm(formula = medv ~ crim + zn + chas + nox + rm+ I(rm^2)+ I(rm^3) + dis + rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_rm_3)
```


```{r}
higher_order_dis_2 = lm(formula = medv ~ crim + zn + chas + nox + rm + dis + I(dis^2)+ rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_dis_2)
```



```{r}
higher_order_dis_3 = lm(formula = medv ~ crim + zn + chas + nox + rm + dis + I(dis^2)+ I(dis^3)+ rad + tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_dis_3)
```


```{r}
higher_order_rad_2 = lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + I(rad^2)+ tax + ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_rad_2)
```


```{r}
higher_order_tax_2 = lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + tax + I(tax^2)+ ptratio + b + lstat + crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_tax_2)
```


```{r}
higher_order_lstat_2 = lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + b + lstat + I(lstat^2)+ crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_lstat_2)
```


```{r}
higher_order_lstat_3 = lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_lstat_3)
```

```{r}
higher_order_lstat_4 = lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_lstat_4)
```


```{r}
higher_order_lstat_5 = lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5)+ crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_lstat_5)
```


```{r}
higher_order_lstat_6 = lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5)+ I(lstat^6)+ crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_lstat_6)
```


```{r}
higher_order_interaction_model = lm(formula = medv ~ crim + I(crim^2)+ zn + chas + nox + I(nox^2)+ rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5)+ crim:zn + crim:chas  +crim:rad+ crim:tax + zn:dis+ chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ rm:lstat+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_interaction_model)
```


```{r}
higher_order_interaction_model_2 = lm(formula = medv ~ crim + I(crim^2) + chas + nox + I(nox^2)+ rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5) + crim:chas  +crim:rad+ crim:tax + chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_interaction_model_2)
```

# Linearity

```{r}
ggplot(higher_order_interaction_model_2, aes(x=.fitted, y=.resid)) +
geom_point() +geom_smooth()+
geom_hline(yintercept = 0)
```


## Equal variance

```{r}
ggplot(higher_order_interaction_model_2, aes(x=.fitted, y=.resid)) +
geom_point(colour = "purple") +
geom_hline(yintercept = 0) +
geom_smooth(colour = "green4")+
ggtitle("Residual plot: Residual vs Fitted values")
```


```{r}
ggplot(higher_order_interaction_model_2, aes(x=.fitted, y=sqrt(abs(.stdresid)))) +
geom_point(colour = "purple") +
geom_hline(yintercept = 0) +
geom_smooth( colour = "green4")+
ggtitle("Scale-Location plot : Standardized Residual vs Fitted values")
```

Based on these plots we can see that the scale-location plot is quite horizontal, and there is not any funneling in the residual plot

```{r}
bptest(higher_order_interaction_model_2)
```

```{r}
higher_order_interaction_model_log = lm(formula = log(medv) ~ crim + I(crim^2) + chas + nox + I(nox^2)+ rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5) + crim:chas  +crim:rad+ crim:tax + chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_interaction_model_log)
```

```{r}
bptest(higher_order_interaction_model_log)
```
```{r}
#Testing for Normality
shapiro.test(residuals(higher_order_interaction_model_log))
```


```{r}
higher_order_interaction_model_log_2 = lm(formula = log(medv) ~ crim + I(crim^2) + chas + nox + I(nox^2)+ rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4) + crim:chas  +crim:rad+ crim:tax + chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ dis:rad + dis:lstat, data = boston_data)
summary(higher_order_interaction_model_log_2)
```

```{r}
bptest(higher_order_interaction_model_log_2)
```

```{r}
#Testing for Normality
shapiro.test(residuals(higher_order_interaction_model_log_2))
```


```{r}
higher_order_interaction_model_log_3 = lm(formula = log(medv) ~ crim + I(crim^2) + chas + nox+ rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4) + crim:chas  +crim:rad+ crim:tax + chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio + dis:lstat, data = boston_data)
summary(higher_order_interaction_model_log_3)
```

```{r}
bptest(higher_order_interaction_model_log_3)
```

```{r}
#Testing for Normality
shapiro.test(residuals(higher_order_interaction_model_log_3))
```



```{r}
library(MASS)

bc=boxcox(higher_order_interaction_model_2,lambda=seq(-1,1))
```


```{r}
#extract best lambda
bestlambda=bc$x[which(bc$y==max(bc$y))]
bestlambda
```


```{r}
higher_order_interaction_model_2_box = lm(formula = (((medv^0.4949495)-1)/0.4949495) ~ crim + I(crim^2) + chas + nox + I(nox^2)+ rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5) + crim:chas  +crim:rad+ crim:tax + chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ dis:rad + dis:lstat+ b:lstat, data = boston_data)
summary(higher_order_interaction_model_2_box)
```

```{r}
bptest(higher_order_interaction_model_2_box)
```


```{r}
#Testing for Normality
shapiro.test(residuals(higher_order_interaction_model_2_box))
```


## Weighted Least Squares Regression Method

```{r}
resid = resid(higher_order_interaction_model_2)
```

```{r}
resid_model = lm(formula = log(resid^2) ~ crim + I(crim^2) + chas + nox + I(nox^2)+ rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5), data = boston_data)
```

```{r}
fitted_var = exp(fitted(resid_model))
weights = 1 / fitted_var
```


```{r}
higher_order_interaction_model_wls = lm(formula = medv ~ crim + I(crim^2) + chas + nox + I(nox^2)+ rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5) + crim:chas  +crim:rad+ crim:tax + chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio+ dis:rad + dis:lstat+ b:lstat, data = boston_data, weights = weights)
summary(higher_order_interaction_model_wls)
```


```{r}
bptest(higher_order_interaction_model_wls)
```


```{r}
#Testing for Normality
shapiro.test(residuals(higher_order_interaction_model_wls))
```





```{r}
higher_order_interaction_model_wls_2 = lm(formula = medv ~ crim + I(crim^2) + chas + nox + rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5) + crim:chas  +crim:rad+ crim:tax + chas:nox +chas:rm + nox:rad + rm:dis + rm:ptratio + dis:lstat+ b:lstat, data = boston_data, weights = weights)
summary(higher_order_interaction_model_wls_2)
```


```{r}
higher_order_interaction_model_wls_3 = lm(formula = medv ~ crim + I(crim^2) + chas + nox + rm+ I(rm^2)+ dis + I(dis^2)+ rad + tax + ptratio + b + lstat + I(lstat^2)+ I(lstat^3)+ I(lstat^4)+ I(lstat^5) + crim:chas  +crim:rad+ crim:tax + chas:nox +chas:rm + rm:dis + rm:ptratio + dis:lstat+ b:lstat, data = boston_data, weights = weights)
summary(higher_order_interaction_model_wls_3)
```

```{r}
bptest(higher_order_interaction_model_wls_3)
```

```{r}
#Testing for Normality
shapiro.test(residuals(higher_order_interaction_model_wls_3))
```

# CONFIRM LINEARITY ASSUMPTION IS STILL GOOD

```{r}
ggplot(higher_order_interaction_model_wls_3, aes(x=.fitted, y=.resid)) +
geom_point(colour = "purple") +
geom_hline(yintercept = 0) +
geom_smooth(colour = "green4")+
ggtitle("Residual plot: Residual vs Fitted values")
```

```{r}
ggplot(higher_order_interaction_model_wls_3, aes(x=.fitted, y=.resid)) +
geom_point() +geom_smooth()+
geom_hline(yintercept = 0)
```
































## NORMALITY

```{r}
ggplot(data=boston_data, aes(residuals(higher_order_interaction_model_2))) +
geom_histogram(breaks = seq(-1,1,by=0.1), col="green3", fill="green4") +
labs(title="Histogram for residuals") +
labs(x="residuals", y="Count")
```


```{r}
ggplot(boston_data, aes(sample=higher_order_interaction_model_2$residuals)) +
stat_qq() + stat_qq_line()
```


```{r}
hist(residuals(higher_order_interaction_model_2))
plot(higher_order_interaction_model_2, which=2)
```

```{r}
#Testing for Normality
shapiro.test(residuals(higher_order_interaction_model_2))
```

## OUTLIERS


```{r}
plot(higher_order_interaction_model_2, 5)
```

Based on this plot everything looks okay
Now I will look at the cooks distance and leverages plots

```{r}
boston_data[cooks.distance(higher_order_interaction_model_2)>0.5,]
```


```{r}
plot(higher_order_interaction_model_2,pch=18,col="red",which=c(4))
```


```{r}
lev=hatvalues(higher_order_interaction_model_2)
p = length(coef(higher_order_interaction_model_2))
n = nrow(boston_data)
outlier2p = lev[lev>(2*p/n)]
outlier3p = lev[lev>(3*p/n)]
print("h_I>2p/n, outliers are")

print(outlier2p)
```



```{r}
print("h_I>3p/n, outliers are")

print(outlier3p)
```

```{r}
plot(rownames(boston_data),lev, main = "Leverage in Boston Housing Dataset", xlab="observation", ylab = "Leverage Value")
abline(h = 2 *p/n, lty = 1)
abline(h = 3 *p/n, lty = 1)
```



It appears we have high leverage points but none of them appear to be particularly influential (no points with a concerning cooks distance). It appears we do not have any outliers that could pose problems.























```{r}
ggsave("bigger_plot.png", plot = p, width = 16, height = 12, dpi = 300)
```







stepwise
ols_backwards
ols_forward
Best Subset
HigherOrder
d. R squared & RSE
e. 

g.  

2.4 Contributions

3. MAIN RESULTS OF THE ANALYSIS
3.1 Results
Individual T-test: 

Hypothesis: 


Based off the values indus and age do not seem relevent. 

We will verify utilizing a global anova f-test: 
```{r}


```
Fail to reject null, they are not relevent. 


Comparison Of R^2 and RSE 

Chas is a factor. 


Final Additive Model: 

```{r}
confint(boston_additive_dropped)
```



4. Conclusion and Discussion
4.1 Approach
4.2 Future Work.
